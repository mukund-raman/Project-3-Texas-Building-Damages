{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Remove existing train/test directories if necessary\n",
    "try:\n",
    "    shutil.rmtree('data/Project3-split/train')\n",
    "    shutil.rmtree('data/Project3-split/test')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create train directories for images\n",
    "Path('data/Project3-split/train/damage').mkdir(parents=True, exist_ok=True)\n",
    "Path('data/Project3-split/train/no_damage').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create test directories for images\n",
    "Path('data/Project3-split/test/damage').mkdir(parents=True, exist_ok=True)\n",
    "Path('data/Project3-split/test/no_damage').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Paths of images for each class (damage and no damage)\n",
    "all_damage_file_paths = os.listdir('data/Project3/damage')\n",
    "all_no_damage_file_paths = os.listdir('data/Project3/no_damage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Create a random 80/20 training testing split for the damage images\n",
    "damage_train_file_paths = random.sample(all_damage_file_paths, int(len(all_damage_file_paths) * 0.8))\n",
    "print(f\"Number of damage images in train: {len(damage_train_file_paths)}\")\n",
    "damage_test_file_paths = [path for path in all_damage_file_paths if path not in damage_train_file_paths]\n",
    "print(f\"Number of damage images in test: {len(damage_test_file_paths)}\")\n",
    "overlap = [path for path in damage_train_file_paths if path in damage_test_file_paths]\n",
    "print(f\"Overlap in damage images (should be zero): {len(overlap)}\")\n",
    "\n",
    "# Create a random 80/20 training testing split for the no damage images\n",
    "no_damage_train_file_paths = random.sample(all_no_damage_file_paths, int(len(all_no_damage_file_paths) * 0.8))\n",
    "print(f\"Number of no damage images in train: {len(no_damage_train_file_paths)}\")\n",
    "no_damage_test_file_paths = [path for path in all_no_damage_file_paths if path not in no_damage_train_file_paths]\n",
    "print(f\"Number of no damage images in test: {len(no_damage_test_file_paths)}\")\n",
    "overlap = [path for path in no_damage_train_file_paths if path in no_damage_test_file_paths]\n",
    "print(f\"Overlap in no damage images (should be zero): {len(overlap)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the images to the train/test directories\n",
    "for path in damage_train_file_paths:\n",
    "    shutil.copyfile(f\"data/Project3/damage/{path}\", f\"data/Project3-split/train/damage/{path}\")\n",
    "for path in damage_test_file_paths:\n",
    "    shutil.copyfile(f\"data/Project3/damage/{path}\", f\"data/Project3-split/test/damage/{path}\")\n",
    "for path in no_damage_train_file_paths:\n",
    "    shutil.copyfile(f\"data/Project3/no_damage/{path}\", f\"data/Project3-split/train/no_damage/{path}\")\n",
    "for path in no_damage_test_file_paths:\n",
    "    shutil.copyfile(f\"data/Project3/no_damage/{path}\", f\"data/Project3-split/test/no_damage/{path}\")\n",
    "\n",
    "# Check counts\n",
    "print(\"Files in train/damage: \", len(os.listdir('data/Project3-split/train/damage')))\n",
    "print(\"Files in train/no_damage: \", len(os.listdir('data/Project3-split/train/no_damage')))\n",
    "print(\"Files in test/damage: \", len(os.listdir('data/Project3-split/test/damage')))\n",
    "print(\"Files in test/no_damage: \", len(os.listdir('data/Project3-split/test/no_damage')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import Rescaling\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "# Path to the training data directory\n",
    "train_data_dir = 'data/Project3-split/train'\n",
    "\n",
    "# Controls size of \"batches\" of images streamed\n",
    "# when accesses the dataset, helps control memory usage\n",
    "batch_size = 32\n",
    "\n",
    "# Image size to which all images will be resized\n",
    "img_height = 150\n",
    "img_width = 150\n",
    "\n",
    "# Create a training dataset from the directory\n",
    "train_ds, val_ds = image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "rescale = Rescaling(1.0/255)\n",
    "\n",
    "train_rescale_ds = train_ds.map(lambda x, y: (rescale(x), y))\n",
    "val_rescale_ds = val_ds.map(lambda x, y: (rescale(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the test dataset\n",
    "test_data_dir = 'data/Project3-split/test'\n",
    "test_ds = image_dataset_from_directory(\n",
    "    test_data_dir,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "test_rescale_ds = test_ds.map(lambda x, y: (rescale(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print image and label shape\n",
    "print(\"Image shape: \", train_rescale_ds.element_spec[0].shape)\n",
    "print(\"Label shape: \", train_rescale_ds.element_spec[1].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
